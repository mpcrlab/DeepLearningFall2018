{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nr7PUxYDgAtk"
   },
   "source": [
    "# Import, define, and mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4_jxvswGp7u"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import tflearn    # try to import tflearn\n",
    "except ImportError:\n",
    "    !pip3 install -q tflearn # install tflearn first\n",
    "    import tflearn # then import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11988
    },
    "colab_type": "code",
    "id": "KHjXPMeIXE3r",
    "outputId": "55ffed19-e15b-4ae0-9480-5c426d4876f8"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -q ffmpeg\n",
    "!pip3 install -q scikit-video\n",
    "import skvideo.io # converts video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nw-uvan0Kk76"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # used for plotting images\n",
    "import numpy as np # to do math functions\n",
    "from glob import glob # helps find files in a folder\n",
    "import os, sys  # to interact with filesystem\n",
    "import cv2\n",
    "import tensorflow as tf  # tensorflow during training\n",
    "from tflearn.activations import relu # rectified linear activation function\n",
    "\n",
    "# normalizes data \n",
    "from tflearn.layers.normalization import batch_normalization as bn\n",
    "from scipy.misc import imread, bytescale, imresize  # image manipulation functions\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d, global_avg_pool\n",
    "from tflearn.layers.estimator import regression  # trainer for the network\n",
    "\n",
    "# turns scalar label into vector where appropriate class is value 1 and others 0\n",
    "from tflearn.data_utils import to_categorical  \n",
    "\n",
    "# makes new images from the ones we have by flipping them, rotating, etc.\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "# to visualize the data space\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy4zkTP8KlR3"
   },
   "outputs": [],
   "source": [
    "    def install_tensorboard_dep():\n",
    "        '''Installs tensorboard to be used in colab.'''\n",
    "        if 'ngrok-stable-linux-amd64.zip' not in os.listdir(os.getcwd()):\n",
    "            !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "            !unzip ngrok-stable-linux-amd64.zip\n",
    "            os.system('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lic_uQkaKnwD"
   },
   "outputs": [],
   "source": [
    "            def montage(x, plot_shape=(15, 15), return_grid=False, cmap='viridis'):\n",
    "                '''\n",
    "                Takes in a 4-D tensor, x, of shape [NxHxWxC] and puts all of the images\n",
    "                together in a single matrix to show as one image. If return_grid is True, \n",
    "                it will not show the matrix, but return it to be used in some other \n",
    "                operations.\n",
    "                '''\n",
    "                \n",
    "                count = 0\n",
    "                if not return_grid:\n",
    "                    scale = [0, 255]\n",
    "                else:\n",
    "                    scale = [0, 1]\n",
    "                \n",
    "                \n",
    "                if len(x.shape) == 4 and x.shape[-1] == 3:\n",
    "                    num, m, n, c = x.shape\n",
    "                else:\n",
    "                    num, m, n = x.shape\n",
    "                    c = 1\n",
    "                    \n",
    "                num = int(np.ceil(np.sqrt(num)))\n",
    "                grid = np.zeros([num*m, num*n, c])\n",
    "                \n",
    "                if c == 1:\n",
    "                    grid = grid[..., 0]\n",
    "                \n",
    "                for i in range(num):\n",
    "                    for j in range(num):\n",
    "                        if count < x.shape[0]:\n",
    "                            if c == 1:\n",
    "                                grid[i*m:i*m+m, j*n:j*n+n] = bytescale(x[count, ...], \n",
    "                                                                                                             low=scale[0], high=scale[1])\n",
    "                            else:\n",
    "                                grid[i*m:i*m+m, j*n:j*n+n, :] = bytescale(x[count, ...],\n",
    "                                                                                                                    low=scale[0], high=scale[1])\n",
    "                            count += 1 \n",
    "                            \n",
    "                if return_grid:\n",
    "                    return grid\n",
    "                else:\n",
    "                    fig = plt.figure(figsize=plot_shape)\n",
    "                    a1 = fig.add_subplot(111)\n",
    "                    a1.set_xticks(np.arange(-0.5, num*n, n))\n",
    "                    a1.set_yticks(np.arange(-0.5, num*m, m))\n",
    "                    a1.set_yticklabels([])\n",
    "                    a1.set_xticklabels([])\n",
    "                    a1.imshow(grid, cmap=cmap)\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ow7Ii2RXKyR_"
   },
   "outputs": [],
   "source": [
    "def start_tensorboard():\n",
    "        '''Starts tensorboard on colaboratory.'''\n",
    "        LOG_DIR = '/tmp/tflearn_logs'    # where the log files will go\n",
    "        get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\n",
    "        get_ipython().system_raw('./ngrok http 6006 &')\n",
    "        ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "        \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shuvYtM65Ozk"
   },
   "outputs": [],
   "source": [
    "def residual_block(incoming, n_filters, filter_size, n_blocks, stride=1):\n",
    "    \n",
    "    for block in range(n_blocks):\n",
    "        n, h, w, c = incoming.get_shape().as_list() # get the shape or input\n",
    "        \n",
    "        if block > 0 and stride > 1:\n",
    "            stride = 1\n",
    "    \n",
    "        # convolution 2\n",
    "        conv1 = conv_2d(incoming, n_filters, filter_size, activation='linear', strides=stride)\n",
    "        conv1_norm = relu(bn(conv1))\n",
    "    \n",
    "        # convolution 2\n",
    "        conv2 = conv_2d(conv1_norm, n_filters, filter_size, activation='linear', strides=1)\n",
    "        conv2_norm = bn(conv2)\n",
    "        \n",
    "        if stride > 1:\n",
    "            incoming = max_pool_2d(incoming, 3, stride)\n",
    "        \n",
    "        if c != n_filters:\n",
    "            incoming = conv_2d(incoming, n_filters, 1, activation='linear', strides=1)\n",
    "    \n",
    "        # elementwise addition between conv2_norm and input\n",
    "        incoming = incoming + conv2_norm\n",
    "    \n",
    "        #relu on addition\n",
    "        incoming = relu(incoming)\n",
    "        \n",
    "        return incoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48cjzPtJCLDv"
   },
   "outputs": [],
   "source": [
    "def video_loader():\n",
    "    vid_names = glob('*.avi') # get all filenames in this location in .avi\n",
    "    print(vid_names)\n",
    "    #keep_interval = 5 # how many frames to skip when going back \n",
    "    num_past_frames = 3\n",
    "    vids = np.zeros([0, 240, 320, num_past_frames])\n",
    "    \n",
    "    for indx, vid_name in enumerate(vid_names):\n",
    "        try:\n",
    "            vid = skvideo.io.vread(vid_name) # read in the image\n",
    "            print(vid.shape)\n",
    "        except ValueError:\n",
    "            continue\n",
    "       \n",
    "        # if video is not correct size, resize it\n",
    "        if vid.shape[1] != 240 or vid.shape[2] != 320:\n",
    "            vid = [imresize(vid[f, ...], [240, 320]) for f in range(vid.shape[0])]\n",
    "     \n",
    "        vid = np.mean(vid, 3, keepdims=True)    #make all frames grayscale\n",
    "        \n",
    "        # make empty array to stack frames together in\n",
    "        vid_stack = np.zeros([vid.shape[0]-num_past_frames, vid.shape[1], vid.shape[2], num_past_frames])\n",
    "        \n",
    "        for frame_id in range((num_past_frames-1), vid.shape[0]):\n",
    "            #pull out past 4 frames\n",
    "            past_1 = vid[frame_id-num_past_frames, ...]\n",
    "            past_2 = vid[frame_id-2*num_past_frames, ...]\n",
    "            \n",
    "            # stack them together in channel dimension\n",
    "            stack = np.concatenate((vid[frame_id, ...], past_1, past_2), 2)\n",
    "            \n",
    "            vid_stack[frame_id-num_past_frames, ...] = stack\n",
    "            \n",
    "                                                    \n",
    "        vids = np.concatenate((vids, vid_stack), 0)\n",
    "        \n",
    "    return vids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6-DlMKE4x7M"
   },
   "outputs": [],
   "source": [
    "# navigate through filesystem to data folders\n",
    "os.chdir('/home/rachel_wong/Documents/HMDB51(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "id": "-miVs6SG5Ubu",
    "outputId": "fa2cef47-441e-455a-bf80-8d81a66ccc27"
   },
   "outputs": [],
   "source": [
    "os.listdir() # list all files and folder in this location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7KVjVuufdfG"
   },
   "source": [
    "# Input training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0PtHIKh6ThO"
   },
   "outputs": [],
   "source": [
    "os.chdir('climb_stairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "jkQ-GlZDCpdO",
    "outputId": "aacc72fd-a892-4855-fb63-75c7aa126036"
   },
   "outputs": [],
   "source": [
    "# call the function to load the images in this directory\n",
    "imgs_train = video_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4m6ZYIv5Crxu",
    "outputId": "925c4ac7-aa7e-42b5-eb5d-ad82a8d01f71"
   },
   "outputs": [],
   "source": [
    "climbstairs_group_imgs_train = imgs_train.shape[0]\n",
    "print(imgs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ts-B3x3tGYvx",
    "outputId": "f145fe1f-0f96-4ff8-a855-f3320c34f961"
   },
   "outputs": [],
   "source": [
    "labels_train = np.zeros([climbstairs_group_imgs_train, ]) # number of rows, number of columns\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train[climbstairs_group_imgs_train:] = 0. # we know that halfway it switches from non-violent to violent so we want it labeled 1 for the bottom half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1016
    },
    "colab_type": "code",
    "id": "SHOXlDYRC4Q-",
    "outputId": "339bdf8e-2020-4e5c-9555-67440ba95fbc"
   },
   "outputs": [],
   "source": [
    "climb_stairs_img_train = imgs_train[0, ...]    # get first stack\n",
    "for i in range(3):    #loop through the five frames in that stack\n",
    "    plt.imshow(climb_stairs_img_train[..., i], cmap='gray')    # plot that number frame in the stack\n",
    "    plt.grid(False) # get rid of grid\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlGc5nk8SUMK"
   },
   "outputs": [],
   "source": [
    "os.chdir('..') # go back a folder\n",
    "os.chdir('run') # go into run folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "ueoVi0FnSj2S",
    "outputId": "0a3344fc-85a6-4707-e5d2-353bc5669d79"
   },
   "outputs": [],
   "source": [
    "imgs_train = np.concatenate((imgs_train, video_loader()), 0) # load for the run folder and then add onto climb_stairs images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cabXTcFbFuqr",
    "outputId": "f6619889-5a7e-4bf5-d090-95b6b8c08428"
   },
   "outputs": [],
   "source": [
    "run_group_imgs_train = imgs_train.shape[0]\n",
    "print(imgs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0vDyOnIPN3p2",
    "outputId": "f876ec1a-01f1-4234-a281-9a146340b1e0"
   },
   "outputs": [],
   "source": [
    "labels_train = np.zeros([run_group_imgs_train, ]) # number of rows, number of columns\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train[climbstairs_group_imgs_train:run_group_imgs_train] = 1. # we know that halfway it switches from non-violent to violent so we want it labeled 1 for the bottom half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1016
    },
    "colab_type": "code",
    "id": "gQuXJITVR5FX",
    "outputId": "d7487ee7-6d21-4455-bde2-be37096149bb"
   },
   "outputs": [],
   "source": [
    "run_img_train = imgs_train[0, ...]        # get first stack\n",
    "for i in range(3):        #loop through the five frames in that stack\n",
    "        plt.imshow(run_img_train[..., i], cmap='gray')        # plot that number frame in the stack\n",
    "        plt.grid(False) # get rid of grid\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Vj-8jLDSU4A"
   },
   "outputs": [],
   "source": [
    "os.chdir('..') # go back a folder\n",
    "os.chdir('ride_bike') # go into walk folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "NabVMI4vSlkE",
    "outputId": "1cc6575b-8505-4194-f786-65475e181ba2"
   },
   "outputs": [],
   "source": [
    "imgs_train = np.concatenate((imgs_train, video_loader()), 0) # load for the walk folder and then add onto climb_stairs images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XKDIwb6ASmBD",
    "outputId": "1e34a63e-26c3-4203-a164-c40ec1882d4b"
   },
   "outputs": [],
   "source": [
    "ridebike_group_imgs_train = imgs_train.shape[0]\n",
    "print(imgs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Pp2pZi-2N8Sp",
    "outputId": "55d2b1b5-4c52-4ea9-ea1c-3c0e4bf5c7d8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_train = np.zeros([ridebike_group_imgs_train, ]) # number of rows, number of columns\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train[run_group_imgs_train:ridebike_group_imgs_train] = 2. # we know that halfway it switches from non-violent to violent so we want it labeled 1 for the bottom half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1016
    },
    "colab_type": "code",
    "id": "eynt9vZ3R-01",
    "outputId": "24024a78-9018-464a-b578-a598a05b5add"
   },
   "outputs": [],
   "source": [
    "ride_bike_img_train = imgs_train[0, ...]        # get first stack\n",
    "for i in range(3):        #loop through the five frames in that stack\n",
    "        plt.imshow(ride_bike_img_train[..., i], cmap='gray')        # plot that number frame in the stack\n",
    "        plt.grid(False) # get rid of grid\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZuwJheuzDh6k",
    "outputId": "07b75856-5723-4535-bef7-8a68bb6134db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(imgs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbBavbSQYER_"
   },
   "outputs": [],
   "source": [
    "from tflearn.data_utils import to_categorical # makes the multi-column labels for us\n",
    "labels_train = to_categorical(labels_train, 3)  # to_categorical(which column to put the 1, number of classes);for number of labels, make the same amount of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BA23FbkuYHwZ",
    "outputId": "5e9e91d7-e805-4f00-816a-9f47b53feff7"
   },
   "outputs": [],
   "source": [
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ojc7ePaCfSkg"
   },
   "source": [
    "# Input test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Taqnq0d7dykq"
   },
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('climb_stairs_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "zCvYOzPfdyk0",
    "outputId": "6d7b91ea-73da-492a-bc52-d87a03bd72f6"
   },
   "outputs": [],
   "source": [
    "# call the function to load the images in this directory\n",
    "imgs_test = video_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dgiMYOOCdyk7",
    "outputId": "b1696c7f-8263-4052-c3ce-be064a2f7c50"
   },
   "outputs": [],
   "source": [
    "climbstairs_group_imgs_test = imgs_test.shape[0]\n",
    "print(imgs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.zeros([climbstairs_group_imgs_test, ])# number of rows, number of columns\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test[climbstairs_group_imgs_test:] = 0. # we know that halfway it switches from non-violent to violent so we want it labeled 1 for the bottom half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1016
    },
    "colab_type": "code",
    "id": "TxW4Bu4hdylM",
    "outputId": "3c8600ca-4996-4936-e1e0-ccd2dc684e1b"
   },
   "outputs": [],
   "source": [
    "climb_stairs_img_test = imgs_test[0, ...]        # get first stack\n",
    "for i in range(3):        #loop through the five frames in that stack\n",
    "        plt.imshow(climb_stairs_img_test[..., i], cmap='gray')        # plot that number frame in the stack\n",
    "        plt.grid(False) # get rid of grid\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBJa7m9qdylV"
   },
   "outputs": [],
   "source": [
    "os.chdir('..') # go back a folder\n",
    "os.chdir('run_test') # go into run folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "dsZv0IifdylY",
    "outputId": "6b564258-674e-4e40-a445-294e19cf276b"
   },
   "outputs": [],
   "source": [
    "imgs_test = np.concatenate((imgs_test, video_loader()), 0) # load for the run folder and then add onto climb_stairs images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YPPW6yR2dyld",
    "outputId": "c421f456-849f-4e6d-c5d4-dee52ff83018"
   },
   "outputs": [],
   "source": [
    "run_group_imgs_test = imgs_test.shape[0]\n",
    "print(imgs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.zeros([run_group_imgs_test, ]) # number of rows, number of columns\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test[climbstairs_group_imgs_test:run_group_imgs_test] = 1. # we know that halfway it switches from non-violent to violent so we want it labeled 1 for the bottom half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1016
    },
    "colab_type": "code",
    "id": "Yyu8bMOUdyl2",
    "outputId": "a966812e-1746-4e96-81cb-17fbd6b71e89"
   },
   "outputs": [],
   "source": [
    "run_img_test = imgs_test[0, ...]        # get first stack\n",
    "for i in range(3):        #loop through the five frames in that stack\n",
    "        plt.imshow(run_img_test[..., i], cmap='gray')        # plot that number frame in the stack\n",
    "        plt.grid(False) # get rid of grid\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCgGf4mGdyl9"
   },
   "outputs": [],
   "source": [
    "os.chdir('..') # go back a folder\n",
    "os.chdir('ride_bike_test') # go into walk folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "4BbabmAIdymA",
    "outputId": "36ba586e-6303-4ba1-dff5-0a89ec69aa23",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs_test = np.concatenate((imgs_test, video_loader()), 0) # load for the walk folder and then add onto climb_stairs images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8_sWHxQAdymO",
    "outputId": "86ccda54-df41-478b-8af9-50cfde6529ec"
   },
   "outputs": [],
   "source": [
    "ridebike_group_imgs_test = imgs_test.shape[0]\n",
    "print(imgs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.zeros([ridebike_group_imgs_test, ]) # number of rows, number of columns\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test[run_group_imgs_test:ridebike_group_imgs_test] = 2. # we know that halfway it switches from non-violent to violent so we want it labeled 1 for the bottom half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1016
    },
    "colab_type": "code",
    "id": "sav1ufvfdymd",
    "outputId": "7fe938c1-aeaa-4fbb-bb45-e04ac20137cf"
   },
   "outputs": [],
   "source": [
    "ride_bike_img_test = imgs_test[0, ...]        # get first stack\n",
    "for i in range(3):        #loop through the five frames in that stack\n",
    "        plt.imshow(ride_bike_img_test[..., i], cmap='gray')        # plot that number frame in the stack\n",
    "        plt.grid(False) # get rid of grid\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(imgs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tflearn.data_utils import to_categorical # makes the multi-column labels for us\n",
    "labels_test = to_categorical(labels_test, 3)  # to_categorical(which column to put the 1, number of classes);for number of labels, make the same amount of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPX7Lf4AfogW"
   },
   "source": [
    "# Training vs testing for x = imgs and y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs_train.shape, labels_train.shape, imgs_test.shape, labels_test.shape)  # print the shapes of training and testing sets\n",
    "print(labels_train[:10, ...])  # print the first 10 labels - value 1 in appropriate spot for that image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPX7Lf4AfogW"
   },
   "source": [
    "# ResNet and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "MC98cPX0YK8u",
    "outputId": "22cb9672-72ea-425e-d553-8b5c4daf4d8a"
   },
   "outputs": [],
   "source": [
    "# create the input layer for the network\n",
    "input_layer = input_data([None, 240, 320, 3])\n",
    "\n",
    "# first convolution --- 120 x 160 x 32\n",
    "conv1 = conv_2d(input_layer, 32, 7, strides=2, activation='relu')\n",
    "\n",
    "# max pooling --- 60 x 80 x 32\n",
    "pool1 = max_pool_2d(conv1, 3, 2)\n",
    "\n",
    "# residual blocks 1-3 --- 60 x 80 x 32\n",
    "residual_block1 = residual_block(pool1, # input to this layer\n",
    "                                 32, # number of features to look for\n",
    "                                 3, # filter size\n",
    "                                 3) # number of residual blocks\n",
    "\n",
    "# residual blocks 4-7 --- 30 x 40 x 64\n",
    "residual_block2 = residual_block(residual_block1, # input \n",
    "                                 64, # num. features to look for\n",
    "                                 3, # filter size\n",
    "                                 4, # number of blocks\n",
    "                                 2) # stride length \n",
    "\n",
    "# residual blocks 8-13 --- 15 x 20 x 128\n",
    "residual_block3 = residual_block(residual_block2,\n",
    "                                 128,\n",
    "                                 3,\n",
    "                                 6, \n",
    "                                 2)\n",
    "\n",
    "# residual blocks 14-16 --- 7 x 10 x 256\n",
    "residual_block4 = residual_block(residual_block3,\n",
    "                                 256,\n",
    "                                 3,\n",
    "                                 3,\n",
    "                                 2)\n",
    "\n",
    "# global average pooling --- 256\n",
    "gap = global_avg_pool(residual_block4)\n",
    "\n",
    "# output layer\n",
    "output_layer = fully_connected(gap, 3, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "UqxlIqOYYN-p",
    "outputId": "2a2c5cdf-93c2-4baf-9b49-4c80af933c05"
   },
   "outputs": [],
   "source": [
    "network = regression(output_layer, optimizer='adam', \n",
    "                     loss='categorical_crossentropy', learning_rate=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "579L7FtPYOpY"
   },
   "outputs": [],
   "source": [
    "# build the network based on the description above\n",
    "model = tflearn.DNN(network, tensorboard_verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7_hjFZm9YkRO",
    "outputId": "2f0e7ce4-0e56-44b3-8c6e-78eb82e3e6bd"
   },
   "outputs": [],
   "source": [
    "# start tensorboard --- might need to run this code cell twice\n",
    "install_tensorboard_dep()\n",
    "start_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "OhZpE2hHYm-Q",
    "outputId": "005e52ce-913b-4572-811f-fd130059340e"
   },
   "outputs": [],
   "source": [
    "model.fit(imgs_train, # input data\n",
    "          labels_train, # corresponding labels\n",
    "          n_epoch=25, # number of times to go through entire dataset\n",
    "          shuffle=True,   # shuffle the images each epoch\n",
    "          validation_set=(imgs_test, labels_test),  # validation dataset/labels\n",
    "          show_metric=True, # show validation accuracy/loss in tensorboard\n",
    "          batch_size=20,   # go through dataset 50 examples at a time\n",
    "          run_id='three_group_diff')  # name that will show up on tensorboard\n",
    "  \n",
    "# saved the trained model for later as the name in red\n",
    "model.save('three_group_diff_ResNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuHUcdIqYnLd"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()  # tensorflow session\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9_RWong_Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
