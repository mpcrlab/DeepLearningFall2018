{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"F12KMGbCl-eN","colab_type":"code","colab":{}},"cell_type":"code","source":["i\n","mport tensorflow as tf\n","import numpy as np\n","import os\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","from scipy.misc import bytescale\n","!pip3 install -q progressbar2\n","from progressbar import ProgressBar\n","\n","import keras\n","from keras.layers import Input # to make input layer\n","from keras.models import Model, Sequential # construct models \n","from keras.layers.core import Dense, Dropout  # fully-connected = Dense \n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.optimizers import Adam \n","from keras import initializers"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3N21wJn5ooux","colab_type":"code","colab":{}},"cell_type":"code","source":["drive.mount('/content/drive') # mount drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I1GFKwBroulI","colab_type":"code","colab":{}},"cell_type":"code","source":["# go to my class folder where this code is\n","os.chdir('drive/My Drive/DeepLearningFall2018') "],"execution_count":0,"outputs":[]},{"metadata":{"id":"xVNaOEeZpFj_","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 100  \n","n_iters = 100000  # number of training iterations \n","noise_size = 100  # how many random numbers to send generator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qOy23Pnwpb-o","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip3 install -q tflearn\n","import tflearn.datasets.mnist as mnist\n","X, _, _, _ = mnist.load_data()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GBu7u6CPp1Oi","colab_type":"code","colab":{}},"cell_type":"code","source":["# print shape of X and its min and max value\n","print(X.shape, np.amin(X), np.amax(X))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Gu4xXaSdqMVD","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.imshow(X[0, ...].reshape([28, 28]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Upe6XUyRqfPC","colab_type":"code","colab":{}},"cell_type":"code","source":["X = (X - 0.5) / .5  # make min value -1 and max 1 in X"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Pp3L39SoqzHU","colab_type":"code","colab":{}},"cell_type":"code","source":["print(np.amin(X), np.amax(X))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d9CnZTfPq4Fd","colab_type":"code","colab":{}},"cell_type":"code","source":["tf.reset_default_graph() # resets the network"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1Ws2bZTsrHLU","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_generator(optimizer):\n","  # this function is going to describe the generator network's operations\n","  generator = Sequential() # create a model where we will stack layers later\n","  \n","  generator.add(Dense(256, # 256 nodes going to examine noise and make responses \n","                      input_dim=noise_size, # number of inputs to this is 100\n","                      # initialize the weights foro this layer with random values\n","                      kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n","  generator.add(LeakyReLU(0.2))\n","  \n","  # another fully-connected layer with 512 nodes to examine 256 previous responses\n","  generator.add(Dense(512))\n","  generator.add(LeakyReLU(0.2))\n","  \n","  # another fully-connected\n","  generator.add(Dense(1024))\n","  generator.add(LeakyReLU(0.2))\n","  \n","  # output layer that is the fake image\n","  generator.add(Dense(784, activation='tanh'))\n","  \n","  # tell the generator how to measure its loss\n","  generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n","  \n","  return generator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WbYC_fCBuH_B","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_discriminator(optimizer):\n","  # this function describes the discriminator network of the GAN\n","  discriminator = Sequential()  # create an empty model to stack layers in\n","  \n","  # first fully-connected layer \n","  discriminator.add(Dense(1024, # 1024 nodes going to examine the input image\n","                          input_dim=784, # 784 nodes in input image\n","                          # initialize weights of these nodes with random values\n","                          kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n","  # activation function\n","  discriminator.add(LeakyReLU(0.2))\n","  discriminator.add(Dropout(0.3)) # drop out 30% of nodes randomly \n","  \n","  # second fully-connected layer\n","  discriminator.add(Dense(512))\n","  discriminator.add(LeakyReLU(0.2))\n","  discriminator.add(Dropout(0.3))\n","  \n","  # third fully-connected layer\n","  discriminator.add(Dense(256))\n","  discriminator.add(LeakyReLU(0.2))\n","  discriminator.add(Dropout(0.3))\n","  \n","  # output layer\n","  discriminator.add(Dense(1, activation='sigmoid'))\n","  \n","  discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n","  \n","  return discriminator"],"execution_count":0,"outputs":[]}]}